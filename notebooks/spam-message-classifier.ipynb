{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52c362d4",
      "metadata": {
        "id": "52c362d4",
        "papermill": {
          "duration": 0.007546,
          "end_time": "2025-07-27T09:36:33.683414",
          "exception": false,
          "start_time": "2025-07-27T09:36:33.675868",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Spam Message Classifier using RoBERTa\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Spam messages are a widespread issue across digital communication platforms, disrupting user experience and trust. This project focuses on building a **spam message classifier** using **RoBERTa**, a state-of-the-art transformer model for natural language understanding.\n",
        "\n",
        "We use the **SMS Spam Collection Dataset** to fine-tune RoBERTa for binary spam classification. This provides a strong and generalized spam detection model suitable for various text-based environments.\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Preprocess and clean SMS messages\n",
        "- Fine-tune a pre-trained RoBERTa model\n",
        "- Evaluate model performance using precision, recall, and F1-score\n",
        "- Save and prepare the trained model for future integration\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“– Dataset\n",
        "\n",
        "**Sources**: \n",
        "1. **[SMS Spam Collection Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)** from UCI Machine Learning Repository\n",
        "2. **[SMS Phishing Dataset](https://data.mendeley.com/datasets/f45bkkt8pr/1)** by Sandhya Mishra & Devpriya Soni (2022)\n",
        "\n",
        "**Combined Dataset Statistics**:\n",
        "- **Total Messages**: 11,498 (entire combined dataset)\n",
        "- **Ham Messages**: 9,669 (84.1%)\n",
        "- **Spam Messages**: 1,829 (15.9%)\n",
        "- **Average Message Length**: ~80 characters\n",
        "- **Language**: English\n",
        "\n",
        "**Dataset Split**:\n",
        "- **Training Set**: 70% (~8,048 messages) - used for model training\n",
        "- **Validation Set**: 15% (~1,725 messages) - used for hyperparameter tuning\n",
        "- **Test Set**: 15% (~1,725 messages) - used for final evaluation (unseen data)\n",
        "\n",
        "**Dataset Details**:\n",
        "- **UCI SMS Spam**: Classic SMS spam detection dataset with ham/spam labels\n",
        "- **Mendeley SMS Phishing**: Modern phishing detection dataset including smishing attacks\n",
        "- **Combined Approach**: Merged datasets for comprehensive spam and phishing detection\n",
        "\n",
        "**Preprocessing Steps**:\n",
        "1. Label encoding (ham â†’ 0, spam â†’ 1, smishing â†’ 1)\n",
        "2. Text cleaning and normalization with Discord-specific preprocessing\n",
        "3. Dataset merging and deduplication\n",
        "4. Train/validation/test split (70/15/15)\n",
        "5. Tokenization with RoBERTa tokenizer\n",
        "6. Dynamic padding and truncation\n",
        "\n",
        "---\n",
        "\n",
        "## Model: RoBERTa\n",
        "\n",
        "We fine-tune a pre-trained `roberta-base` model using Hugging Face Transformers. The model is trained on the processed SMS dataset with a binary classification head.\n",
        "\n",
        "---\n",
        "\n",
        "## Evaluation Metrics\n",
        "\n",
        "We evaluate the model using standard classification metrics:\n",
        "\n",
        "- **Precision**\n",
        "- **Recall**\n",
        "- **F1-score**\n",
        "- **Accuracy**\n",
        "\n",
        "### Acceptance Criteria\n",
        "\n",
        "To ensure the model's reliability in real-world deployment, we define the following criterion:\n",
        "\n",
        "> **The model will be considered acceptable if the F1-score for the `spam` class exceeds 0.95 on the test dataset.**\n",
        "\n",
        "This threshold ensures the classifier effectively balances **precision** and **recall** for detecting spam, minimizing both false positives and false negatives.\n",
        "\n",
        "---\n",
        "\n",
        "## Output\n",
        "\n",
        "The trained model, tokenizer, and preprocessing pipeline are saved in Hugging Face format, ready for inference or deployment.\n",
        "\n",
        "You can find the trained model here:  \n",
        "ðŸ‘‰ **[roshana1s/spam-message-classifier on Hugging Face](https://huggingface.co/roshana1s/spam-message-classifier)**\n",
        "\n",
        "---\n",
        "\n",
        "## Integration with Amy (Discord Bot)\n",
        "\n",
        "This spam classifier will be integrated into **Amy** â€” an intelligent Discord bot capable of:\n",
        "\n",
        "- Detecting spam messages in real-time using this RoBERTa-based model\n",
        "- Identifying toxic or harmful messages (via a **separate toxicity detection model**)\n",
        "\n",
        "This project serves as the core backend for Amyâ€™s moderation capabilities in Discord servers.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795fc4ef",
      "metadata": {
        "id": "795fc4ef",
        "papermill": {
          "duration": 0.023219,
          "end_time": "2025-07-27T09:38:00.295741",
          "exception": false,
          "start_time": "2025-07-27T09:38:00.272522",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Preparing the tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ANLmNakk9TT7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANLmNakk9TT7",
        "outputId": "55e7ddf9-9a6f-4841-cda0-268008bb52c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets optuna scikit-learn matplotlib seaborn pandas torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b2441fd3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:00.343162Z",
          "iopub.status.busy": "2025-07-27T09:38:00.342291Z",
          "iopub.status.idle": "2025-07-27T09:38:45.146281Z",
          "shell.execute_reply": "2025-07-27T09:38:45.145665Z"
        },
        "id": "b2441fd3",
        "papermill": {
          "duration": 44.828804,
          "end_time": "2025-07-27T09:38:45.147710",
          "exception": false,
          "start_time": "2025-07-27T09:38:00.318906",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# General libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sklearn - preprocessing and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Hugging Face Transformers\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# Dataset\n",
        "from datasets import Dataset\n",
        "\n",
        "# PyTorch (used under the hood by transformers)\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Optuna for hyperparameter tuning\n",
        "import optuna\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the root directory to sys.path\n",
        "sys.path.append(os.path.abspath('..'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3d12b018",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.194150Z",
          "iopub.status.busy": "2025-07-27T09:38:45.193439Z",
          "iopub.status.idle": "2025-07-27T09:38:45.198372Z",
          "shell.execute_reply": "2025-07-27T09:38:45.197633Z"
        },
        "id": "3d12b018",
        "papermill": {
          "duration": 0.028646,
          "end_time": "2025-07-27T09:38:45.199555",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.170909",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    text = re.sub(r\"(https?:\\/\\/)?(www\\.)?(discord\\.(gg|io|me|li)|discordapp\\.com\\/invite)\\/\\S+\", \"<DISCORD_INVITE>\", text)  # Discord invites first\n",
        "    text = re.sub(r\"(https?://\\S+|www\\.\\S+)\", \"<URL>\", text)  # URLs\n",
        "    text = re.sub(r\"<@!?\\d+>\", \"<USER>\", text)                # Mentions\n",
        "    text = re.sub(r\"<a?:\\w+:\\d+>\", \"<EMOJI>\", text)           # Emojis\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "294362a8",
      "metadata": {
        "id": "294362a8",
        "papermill": {
          "duration": 0.02216,
          "end_time": "2025-07-27T09:38:45.244177",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.222017",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nfFHZZqX-TIQ",
      "metadata": {
        "id": "nfFHZZqX-TIQ"
      },
      "source": [
        "### Load Dataset 1 - UCI SMS Spam dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "75c4f488",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.334760Z",
          "iopub.status.busy": "2025-07-27T09:38:45.334333Z",
          "iopub.status.idle": "2025-07-27T09:38:45.396486Z",
          "shell.execute_reply": "2025-07-27T09:38:45.395722Z"
        },
        "id": "75c4f488",
        "outputId": "9cc331c3-d4a2-44dc-b4ed-57a723465175",
        "papermill": {
          "duration": 0.13164,
          "end_time": "2025-07-27T09:38:45.397691",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.266051",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"v1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"v2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"Did u download the fring app?\",\n          \"Pass dis to all ur contacts n see wat u get! Red;i'm in luv wid u. Blue;u put a smile on my face. Purple;u r realy hot. Pink;u r so swt. Orange;i thnk i lyk u. Green;i realy wana go out wid u. Yelow;i wnt u bck. Black;i'm jealous of u. Brown;i miss you Nw plz giv me one color\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 43,\n        \"samples\": [\n          \" GOD said\",\n          \" SHE SHUDVETOLD U. DID URGRAN KNOW?NEWAY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \" \\\\\\\"OH No! COMPETITION\\\\\\\". Who knew\",\n          \" why to miss them\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"GNT:-)\\\"\",\n          \" one day these two will become FREINDS FOREVER!\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df1"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-268829b4-cb9d-453f-bab8-5f4b1e1dbb81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-268829b4-cb9d-453f-bab8-5f4b1e1dbb81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-268829b4-cb9d-453f-bab8-5f4b1e1dbb81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-268829b4-cb9d-453f-bab8-5f4b1e1dbb81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eb370f62-962e-4d4f-aeaa-03e974e58b64\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb370f62-962e-4d4f-aeaa-03e974e58b64')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eb370f62-962e-4d4f-aeaa-03e974e58b64 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = pd.read_csv(\"/content/data/sms_spam_uci.csv\", encoding=\"latin1\")\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "4d96bae4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.445040Z",
          "iopub.status.busy": "2025-07-27T09:38:45.444754Z",
          "iopub.status.idle": "2025-07-27T09:38:45.464333Z",
          "shell.execute_reply": "2025-07-27T09:38:45.463723Z"
        },
        "id": "4d96bae4",
        "outputId": "1d0bb8d9-cca0-4778-ce84-792cbc3a9c97",
        "papermill": {
          "duration": 0.043681,
          "end_time": "2025-07-27T09:38:45.465408",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.421727",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"Did u download the fring app?\",\n          \"Pass dis to all ur contacts n see wat u get! Red;i'm in luv wid u. Blue;u put a smile on my face. Purple;u r realy hot. Pink;u r so swt. Orange;i thnk i lyk u. Green;i realy wana go out wid u. Yelow;i wnt u bck. Black;i'm jealous of u. Brown;i miss you Nw plz giv me one color\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df1"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2f18bf5d-1a17-4981-8877-096830ee8afd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f18bf5d-1a17-4981-8877-096830ee8afd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f18bf5d-1a17-4981-8877-096830ee8afd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f18bf5d-1a17-4981-8877-096830ee8afd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-261a0fcb-2e9f-40d2-9111-eba1dcaf72b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-261a0fcb-2e9f-40d2-9111-eba1dcaf72b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-261a0fcb-2e9f-40d2-9111-eba1dcaf72b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1 = df1[['v1', 'v2']]  # Keep only label and message\n",
        "df1.columns = ['label', 'text']  # Rename for consistency\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X1YXuGQq-bbr",
      "metadata": {
        "id": "X1YXuGQq-bbr"
      },
      "source": [
        "### Load Dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "PxoFyUzF-eiL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PxoFyUzF-eiL",
        "outputId": "88a46c11-609e-4da4-8e91-f15077871b3d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 5971,\n  \"fields\": [\n    {\n      \"column\": \"LABEL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Smishing\",\n          \"smishing\",\n          \"spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TEXT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5949,\n        \"samples\": [\n          \"Ur cash-balance is currently 500 pounds - to maximize ur cash-in now send CASH to 86688 only 150p/msg. CC: 08718720201\",\n          \"4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths+? Call MobilesDirect free on 08000938768 to update now!\",\n          \"K da:)how many page you want?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EMAIL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PHONE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df2"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-777878b0-7488-42bb-aef1-b24d2b8ab656\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>URL</th>\n",
              "      <th>EMAIL</th>\n",
              "      <th>PHONE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>What's up? Do you want me to come online? If y...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>So u workin overtime nigpun?</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Also sir, i sent you an email about how to log...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Smishing</td>\n",
              "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-777878b0-7488-42bb-aef1-b24d2b8ab656')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-777878b0-7488-42bb-aef1-b24d2b8ab656 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-777878b0-7488-42bb-aef1-b24d2b8ab656');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-62ca9cb2-50a0-46a0-b618-d9ea8ea367c8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62ca9cb2-50a0-46a0-b618-d9ea8ea367c8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-62ca9cb2-50a0-46a0-b618-d9ea8ea367c8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      LABEL                                               TEXT URL EMAIL PHONE\n",
              "0       ham  Your opinion about me? 1. Over 2. Jada 3. Kusr...  No    No    No\n",
              "1       ham  What's up? Do you want me to come online? If y...  No    No    No\n",
              "2       ham                       So u workin overtime nigpun?  No    No    No\n",
              "3       ham  Also sir, i sent you an email about how to log...  No    No    No\n",
              "4  Smishing  Please Stay At Home. To encourage the notion o...  No    No    No"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.read_csv(\"/content/data/Dataset_5971.csv\")\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "mxg-LyO1-m15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mxg-LyO1-m15",
        "outputId": "eaea035b-d28d-42bf-8c5f-6fe67a13eec3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 5971,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Smishing\",\n          \"smishing\",\n          \"spam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5949,\n        \"samples\": [\n          \"Ur cash-balance is currently 500 pounds - to maximize ur cash-in now send CASH to 86688 only 150p/msg. CC: 08718720201\",\n          \"4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths+? Call MobilesDirect free on 08000938768 to update now!\",\n          \"K da:)how many page you want?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df2"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cd1d69c2-2ad6-494f-bad8-024197a57305\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>What's up? Do you want me to come online? If y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>So u workin overtime nigpun?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Also sir, i sent you an email about how to log...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Smishing</td>\n",
              "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd1d69c2-2ad6-494f-bad8-024197a57305')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd1d69c2-2ad6-494f-bad8-024197a57305 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd1d69c2-2ad6-494f-bad8-024197a57305');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-de10cf59-530b-4ecf-9aa0-a562a9930325\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de10cf59-530b-4ecf-9aa0-a562a9930325')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-de10cf59-530b-4ecf-9aa0-a562a9930325 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      label                                               text\n",
              "0       ham  Your opinion about me? 1. Over 2. Jada 3. Kusr...\n",
              "1       ham  What's up? Do you want me to come online? If y...\n",
              "2       ham                       So u workin overtime nigpun?\n",
              "3       ham  Also sir, i sent you an email about how to log...\n",
              "4  Smishing  Please Stay At Home. To encourage the notion o..."
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = df2[['LABEL', 'TEXT']]  # Keep only label and message\n",
        "df2.columns = ['label', 'text']  # Rename for consistency\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "2V_51nGO-wAe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2V_51nGO-wAe",
        "outputId": "7be1f982-6a32-4d1b-cfbb-dbaa786b169f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 5971,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"spam\",\n          \"smishing\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5949,\n        \"samples\": [\n          \"Ur cash-balance is currently 500 pounds - to maximize ur cash-in now send CASH to 86688 only 150p/msg. CC: 08718720201\",\n          \"4mths half price Orange line rental & latest camera phones 4 FREE. Had your phone 11mths+? Call MobilesDirect free on 08000938768 to update now!\",\n          \"K da:)how many page you want?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df2"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cec2fd61-56d1-44e8-b03a-758f09b01fb3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>What's up? Do you want me to come online? If y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>So u workin overtime nigpun?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Also sir, i sent you an email about how to log...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cec2fd61-56d1-44e8-b03a-758f09b01fb3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cec2fd61-56d1-44e8-b03a-758f09b01fb3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cec2fd61-56d1-44e8-b03a-758f09b01fb3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b6e8b1d2-aef8-4f1e-83d8-30d5cf2ac006\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6e8b1d2-aef8-4f1e-83d8-30d5cf2ac006')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b6e8b1d2-aef8-4f1e-83d8-30d5cf2ac006 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Your opinion about me? 1. Over 2. Jada 3. Kusr...\n",
              "1   ham  What's up? Do you want me to come online? If y...\n",
              "2   ham                       So u workin overtime nigpun?\n",
              "3   ham  Also sir, i sent you an email about how to log...\n",
              "4  spam  Please Stay At Home. To encourage the notion o..."
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make Smishing as spam as well\n",
        "df2['label'] = df2['label'].apply(lambda x: 'spam' if x == 'Smishing' else x)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "5Ow_kpbM_E50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5Ow_kpbM_E50",
        "outputId": "362457b5-51c9-4ef8-9ecb-b8f1792f6c22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11543,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"spam\",\n          \"smishing\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6808,\n        \"samples\": [\n          \"Hey what how about your project. Started aha da.\",\n          \"Yetunde, i'm sorry but moji and i seem too busy to be able to go shopping. Can you just please find some other way to get what you wanted us to get. Please forgive me. You can reply free via yahoo messenger.\",\n          \"Yup i'm elaborating on the safety aspects and some other issues..\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-638ba294-db82-44b3-9fe0-b670431a2451\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-638ba294-db82-44b3-9fe0-b670431a2451')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-638ba294-db82-44b3-9fe0-b670431a2451 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-638ba294-db82-44b3-9fe0-b670431a2451');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47d5ed60-8936-45f1-916b-324a7596b729\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47d5ed60-8936-45f1-916b-324a7596b729')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47d5ed60-8936-45f1-916b-324a7596b729 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Merge df1 and df2 as df\n",
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "mozH7Abl_LZS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mozH7Abl_LZS",
        "outputId": "456aa7e7-e4f8-4f41-b334-056d36132df6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Becoz its  &lt;#&gt;  jan whn al the post ofice is in holiday so she cn go fr the post ofice...got it duffer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-116e8125-2657-4ca5-ad3a-0f945c7a4dd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>ham</td>\n",
              "      <td>:( but your not here....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>ham</td>\n",
              "      <td>Becoz its  &amp;lt;#&amp;gt;  jan whn al the post ofic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>ham</td>\n",
              "      <td>Its a valentine game. . . send dis msg to all ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11541</th>\n",
              "      <td>ham</td>\n",
              "      <td>We r outside already.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11542</th>\n",
              "      <td>ham</td>\n",
              "      <td>The Xmas story is peace.. The Xmas msg is love...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-116e8125-2657-4ca5-ad3a-0f945c7a4dd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-116e8125-2657-4ca5-ad3a-0f945c7a4dd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-116e8125-2657-4ca5-ad3a-0f945c7a4dd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d8507da0-8981-46ae-aa7f-b4906787d102\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8507da0-8981-46ae-aa7f-b4906787d102')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d8507da0-8981-46ae-aa7f-b4906787d102 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      label                                               text\n",
              "11538   ham                           :( but your not here....\n",
              "11539   ham  Becoz its  &lt;#&gt;  jan whn al the post ofic...\n",
              "11540   ham  Its a valentine game. . . send dis msg to all ...\n",
              "11541   ham                              We r outside already.\n",
              "11542   ham  The Xmas story is peace.. The Xmas msg is love..."
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "3028ae3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.513117Z",
          "iopub.status.busy": "2025-07-27T09:38:45.512858Z",
          "iopub.status.idle": "2025-07-27T09:38:45.521631Z",
          "shell.execute_reply": "2025-07-27T09:38:45.520940Z"
        },
        "id": "3028ae3a",
        "outputId": "dffab787-f63a-4686-e27a-411cf72086fd",
        "papermill": {
          "duration": 0.03409,
          "end_time": "2025-07-27T09:38:45.522829",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.488739",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11543,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3657583209256806,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6808,\n        \"samples\": [\n          \"Hey what how about your project. Started aha da.\",\n          \"Yetunde, i'm sorry but moji and i seem too busy to be able to go shopping. Can you just please find some other way to get what you wanted us to get. Please forgive me. You can reply free via yahoo messenger.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-91b24b16-5253-4163-a17a-3ab2f554b29d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91b24b16-5253-4163-a17a-3ab2f554b29d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91b24b16-5253-4163-a17a-3ab2f554b29d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91b24b16-5253-4163-a17a-3ab2f554b29d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1070d049-6220-4cf7-89af-c9edbed28f8f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1070d049-6220-4cf7-89af-c9edbed28f8f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1070d049-6220-4cf7-89af-c9edbed28f8f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0    0.0  Go until jurong point, crazy.. Available only ...\n",
              "1    0.0                      Ok lar... Joking wif u oni...\n",
              "2    1.0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    0.0  U dun say so early hor... U c already then say...\n",
              "4    0.0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert labels to numbers\n",
        "# Convert spam/ham to 1/0\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "3ae5e686",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.573618Z",
          "iopub.status.busy": "2025-07-27T09:38:45.573177Z",
          "iopub.status.idle": "2025-07-27T09:38:45.585715Z",
          "shell.execute_reply": "2025-07-27T09:38:45.585087Z"
        },
        "id": "3ae5e686",
        "outputId": "df56ec00-5ab1-4f15-e87c-44ce83462371",
        "papermill": {
          "duration": 0.038089,
          "end_time": "2025-07-27T09:38:45.586872",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.548783",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>9669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1829</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0.0    9669\n",
              "1.0    1829\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "87b2ed1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.639708Z",
          "iopub.status.busy": "2025-07-27T09:38:45.639157Z",
          "iopub.status.idle": "2025-07-27T09:38:45.655679Z",
          "shell.execute_reply": "2025-07-27T09:38:45.654879Z"
        },
        "id": "87b2ed1c",
        "outputId": "8d5483c5-8f55-48a9-8f35-c0951697f5e4",
        "papermill": {
          "duration": 0.0445,
          "end_time": "2025-07-27T09:38:45.656851",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.612351",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11543 entries, 0 to 11542\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   label   11498 non-null  float64\n",
            " 1   text    11543 non-null  object \n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 180.5+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "df8c16ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.710124Z",
          "iopub.status.busy": "2025-07-27T09:38:45.709370Z",
          "iopub.status.idle": "2025-07-27T09:38:45.716332Z",
          "shell.execute_reply": "2025-07-27T09:38:45.715528Z"
        },
        "id": "df8c16ec",
        "outputId": "109d867b-3449-41ff-b6b8-6a8167230940",
        "papermill": {
          "duration": 0.034807,
          "end_time": "2025-07-27T09:38:45.717500",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.682693",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label    45\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "LgC78hn8_eMs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgC78hn8_eMs",
        "outputId": "5fb65e52-c97d-4644-fad4-91288df4eeff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label    0\n",
            "text     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Drop rows with missing labels\n",
        "df.dropna(subset=['label'], inplace=True)\n",
        "\n",
        "# Verify that there are no more missing values in the 'label' column\n",
        "print(df.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "gvi7REMsNvf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gvi7REMsNvf0",
        "outputId": "bafb4262-6299-4baa-d082-58ec95e52810"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11498,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6775,\n        \"samples\": [\n          \"You are mistaken\\ufffd.The fact that you  felt like i would do it to hurt you shows you really don't know me at all.\",\n          \"how's things? Just a quick question.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1e924f72-01eb-4475-b051-fb9870b6553c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e924f72-01eb-4475-b051-fb9870b6553c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e924f72-01eb-4475-b051-fb9870b6553c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e924f72-01eb-4475-b051-fb9870b6553c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f0d7aef8-92eb-4755-ba5d-de54d370a9cd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0d7aef8-92eb-4755-ba5d-de54d370a9cd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f0d7aef8-92eb-4755-ba5d-de54d370a9cd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make label to int\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "61e672ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:45.766590Z",
          "iopub.status.busy": "2025-07-27T09:38:45.765890Z",
          "iopub.status.idle": "2025-07-27T09:38:46.077644Z",
          "shell.execute_reply": "2025-07-27T09:38:46.076868Z"
        },
        "id": "61e672ce",
        "outputId": "76e9a36e-80de-44f8-8999-e9e4549a8b20",
        "papermill": {
          "duration": 0.337437,
          "end_time": "2025-07-27T09:38:46.078854",
          "exception": false,
          "start_time": "2025-07-27T09:38:45.741417",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df[\"label\"].value_counts().plot(kind='bar', figsize=(6,4))\n",
        "plt.title(\"Spam vs Ham Message Counts\")\n",
        "plt.xlabel(\"Message Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(ticks=[0,1], labels=['Ham', 'Spam'], rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a11b9fb",
      "metadata": {
        "id": "2a11b9fb",
        "papermill": {
          "duration": 0.02777,
          "end_time": "2025-07-27T09:38:46.130512",
          "exception": false,
          "start_time": "2025-07-27T09:38:46.102742",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We can clearly see, there is class imbalance between `spam` and `ham`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "3ae3131f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:46.201929Z",
          "iopub.status.busy": "2025-07-27T09:38:46.201542Z",
          "iopub.status.idle": "2025-07-27T09:38:46.653043Z",
          "shell.execute_reply": "2025-07-27T09:38:46.652281Z"
        },
        "id": "3ae3131f",
        "outputId": "948d5dec-5c39-4496-9e0f-72a9bae88822",
        "papermill": {
          "duration": 0.486682,
          "end_time": "2025-07-27T09:38:46.654415",
          "exception": false,
          "start_time": "2025-07-27T09:38:46.167733",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df[\"len\"] = df[\"text\"].apply(len)\n",
        "\n",
        "# Plot text length distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data=df, x=\"len\", hue='label', bins=50, kde=True, palette='pastel')\n",
        "plt.title(\"Text Length Distribution by Label\")\n",
        "plt.xlabel(\"Message Length (Characters)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ecd6796",
      "metadata": {
        "id": "0ecd6796",
        "papermill": {
          "duration": 0.023855,
          "end_time": "2025-07-27T09:38:46.704207",
          "exception": false,
          "start_time": "2025-07-27T09:38:46.680352",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "1ecdf9bd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:46.753057Z",
          "iopub.status.busy": "2025-07-27T09:38:46.752467Z",
          "iopub.status.idle": "2025-07-27T09:38:46.833871Z",
          "shell.execute_reply": "2025-07-27T09:38:46.833142Z"
        },
        "id": "1ecdf9bd",
        "papermill": {
          "duration": 0.106731,
          "end_time": "2025-07-27T09:38:46.835072",
          "exception": false,
          "start_time": "2025-07-27T09:38:46.728341",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "df[\"text\"] = df[\"text\"].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "0e463f22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:46.883578Z",
          "iopub.status.busy": "2025-07-27T09:38:46.883343Z",
          "iopub.status.idle": "2025-07-27T09:38:46.892390Z",
          "shell.execute_reply": "2025-07-27T09:38:46.891658Z"
        },
        "id": "0e463f22",
        "outputId": "fae36f2f-9296-47a6-e10f-b2504d974137",
        "papermill": {
          "duration": 0.034371,
          "end_time": "2025-07-27T09:38:46.893484",
          "exception": false,
          "start_time": "2025-07-27T09:38:46.859113",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11498,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6546,\n        \"samples\": [\n          \"I thought i'd get him a watch, just cos thats the kind of thing u get4an18th. And he loves so much!\",\n          \"Free entry in 2 a weekly comp for a chance to win an ipod. Txt POD to 80182 to get entry call 08452810073\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 2,\n        \"max\": 910,\n        \"num_unique_values\": 297,\n        \"samples\": [\n          281,\n          790\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0e564038-68a0-4e85-b08c-cb833564dac3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>0</td>\n",
              "      <td>:( but your not here....</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>0</td>\n",
              "      <td>Becoz its &amp;lt;#&amp;gt; jan whn al the post ofice ...</td>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>0</td>\n",
              "      <td>Its a valentine game. . . send dis msg to all ...</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11541</th>\n",
              "      <td>0</td>\n",
              "      <td>We r outside already.</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11542</th>\n",
              "      <td>0</td>\n",
              "      <td>The Xmas story is peace.. The Xmas msg is love...</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11498 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e564038-68a0-4e85-b08c-cb833564dac3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e564038-68a0-4e85-b08c-cb833564dac3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e564038-68a0-4e85-b08c-cb833564dac3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-31f78144-44a6-47f5-8216-2e12005f2cb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31f78144-44a6-47f5-8216-2e12005f2cb2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-31f78144-44a6-47f5-8216-2e12005f2cb2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9ae9d4fa-c262-4edb-8b30-3760b7f69516\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9ae9d4fa-c262-4edb-8b30-3760b7f69516 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       label                                               text  len\n",
              "0          0  Go until jurong point, crazy.. Available only ...  111\n",
              "1          0                      Ok lar... Joking wif u oni...   29\n",
              "2          1  Free entry in 2 a wkly comp to win FA Cup fina...  155\n",
              "3          0  U dun say so early hor... U c already then say...   49\n",
              "4          0  Nah I don't think he goes to usf, he lives aro...   61\n",
              "...      ...                                                ...  ...\n",
              "11538      0                           :( but your not here....   24\n",
              "11539      0  Becoz its &lt;#&gt; jan whn al the post ofice ...  108\n",
              "11540      0  Its a valentine game. . . send dis msg to all ...  150\n",
              "11541      0                              We r outside already.   21\n",
              "11542      0  The Xmas story is peace.. The Xmas msg is love...  129\n",
              "\n",
              "[11498 rows x 3 columns]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f5b4471",
      "metadata": {
        "id": "9f5b4471",
        "papermill": {
          "duration": 0.024114,
          "end_time": "2025-07-27T09:38:46.941624",
          "exception": false,
          "start_time": "2025-07-27T09:38:46.917510",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "716e1e32",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:46.989519Z",
          "iopub.status.busy": "2025-07-27T09:38:46.989241Z",
          "iopub.status.idle": "2025-07-27T09:38:47.000176Z",
          "shell.execute_reply": "2025-07-27T09:38:46.999315Z"
        },
        "id": "716e1e32",
        "papermill": {
          "duration": 0.036354,
          "end_time": "2025-07-27T09:38:47.001385",
          "exception": false,
          "start_time": "2025-07-27T09:38:46.965031",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Split data - preserve class distribution\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=df['label']  # Maintain class balance in splits\n",
        ")\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    stratify=temp_df['label']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "e5ac3a48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:47.050522Z",
          "iopub.status.busy": "2025-07-27T09:38:47.050265Z",
          "iopub.status.idle": "2025-07-27T09:38:47.054776Z",
          "shell.execute_reply": "2025-07-27T09:38:47.054240Z"
        },
        "id": "e5ac3a48",
        "outputId": "8e42fc8c-face-4748-eaf5-be1a01f058c2",
        "papermill": {
          "duration": 0.029873,
          "end_time": "2025-07-27T09:38:47.055775",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.025902",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8048, 3), (1725, 3), (1725, 3))"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape, val_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "9bc4415c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:47.103626Z",
          "iopub.status.busy": "2025-07-27T09:38:47.103407Z",
          "iopub.status.idle": "2025-07-27T09:38:47.109211Z",
          "shell.execute_reply": "2025-07-27T09:38:47.108490Z"
        },
        "id": "9bc4415c",
        "outputId": "b3f55594-5388-4208-c3d4-3e2015339eb8",
        "papermill": {
          "duration": 0.031003,
          "end_time": "2025-07-27T09:38:47.110405",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.079402",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    6768\n",
              "1    1280\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "223e15a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:47.160019Z",
          "iopub.status.busy": "2025-07-27T09:38:47.159759Z",
          "iopub.status.idle": "2025-07-27T09:38:47.165609Z",
          "shell.execute_reply": "2025-07-27T09:38:47.164816Z"
        },
        "id": "223e15a6",
        "outputId": "17935744-a35b-4b5e-8ade-47c6ca3307be",
        "papermill": {
          "duration": 0.031697,
          "end_time": "2025-07-27T09:38:47.167145",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.135448",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    1450\n",
              "1     275\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "428fe9f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:47.226273Z",
          "iopub.status.busy": "2025-07-27T09:38:47.225759Z",
          "iopub.status.idle": "2025-07-27T09:38:47.231635Z",
          "shell.execute_reply": "2025-07-27T09:38:47.230891Z"
        },
        "id": "428fe9f2",
        "outputId": "0682b027-6fb9-4dff-f80f-e570aca4fee5",
        "papermill": {
          "duration": 0.03292,
          "end_time": "2025-07-27T09:38:47.232826",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.199906",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    1451\n",
              "1     274\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "a76a6553",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:47.281626Z",
          "iopub.status.busy": "2025-07-27T09:38:47.281163Z",
          "iopub.status.idle": "2025-07-27T09:38:47.289170Z",
          "shell.execute_reply": "2025-07-27T09:38:47.288440Z"
        },
        "id": "a76a6553",
        "outputId": "c2373571-4548-4685-eb17-1732c28c1aca",
        "papermill": {
          "duration": 0.033594,
          "end_time": "2025-07-27T09:38:47.290208",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.256614",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 8048,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5550,\n        \"samples\": [\n          \"Dear Voucher Holder, To claim this weeks offer, at you PC please go to <URL> Ts&Cs apply.\",\n          \"I\\u0089\\u00db\\u00f7ve got some salt, you can rub it in my open wounds if you like!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58,\n        \"min\": 2,\n        \"max\": 910,\n        \"num_unique_values\": 283,\n        \"samples\": [\n          67,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e36c9479-79b0-4ccd-a7ca-b483a53dd900\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11294</th>\n",
              "      <td>0</td>\n",
              "      <td>Thank you. And by the way, I just lost.</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>1</td>\n",
              "      <td>You are a winner U have been specially selecte...</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3089</th>\n",
              "      <td>0</td>\n",
              "      <td>Am going to take bath ill place the key in win...</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5980</th>\n",
              "      <td>0</td>\n",
              "      <td>Gudnite....tc...practice going on</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3954</th>\n",
              "      <td>0</td>\n",
              "      <td>I knew it... U slept v late yest? Wake up so l...</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10820</th>\n",
              "      <td>1</td>\n",
              "      <td>3. You have received your mobile content. Enjoy</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8210</th>\n",
              "      <td>0</td>\n",
              "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>0</td>\n",
              "      <td>When people see my msgs, They think Iam addict...</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7135</th>\n",
              "      <td>0</td>\n",
              "      <td>It will stop on itself. I however suggest she ...</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10789</th>\n",
              "      <td>0</td>\n",
              "      <td>Actually i deleted my old website..now i m blo...</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8048 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e36c9479-79b0-4ccd-a7ca-b483a53dd900')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e36c9479-79b0-4ccd-a7ca-b483a53dd900 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e36c9479-79b0-4ccd-a7ca-b483a53dd900');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f4be3423-6376-486d-95f6-ff684f1bd06b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4be3423-6376-486d-95f6-ff684f1bd06b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f4be3423-6376-486d-95f6-ff684f1bd06b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5d0e585e-60ea-471f-a272-a0e8d38e3afe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5d0e585e-60ea-471f-a272-a0e8d38e3afe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       label                                               text  len\n",
              "11294      0            Thank you. And by the way, I just lost.   39\n",
              "159        1  You are a winner U have been specially selecte...  146\n",
              "3089       0  Am going to take bath ill place the key in win...   52\n",
              "5980       0                  Gudnite....tc...practice going on   33\n",
              "3954       0  I knew it... U slept v late yest? Wake up so l...   52\n",
              "...      ...                                                ...  ...\n",
              "10820      1    3. You have received your mobile content. Enjoy   47\n",
              "8210       0  Yes i have. So that's why u texted. Pshew...mi...   63\n",
              "917        0  When people see my msgs, They think Iam addict...  148\n",
              "7135       0  It will stop on itself. I however suggest she ...  111\n",
              "10789      0  Actually i deleted my old website..now i m blo...   80\n",
              "\n",
              "[8048 rows x 3 columns]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3dbf921",
      "metadata": {
        "id": "d3dbf921",
        "papermill": {
          "duration": 0.023866,
          "end_time": "2025-07-27T09:38:47.338903",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.315037",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We know that in this dataset, class imbalance is high. So, we need to have weighted trainer for that."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3905214b",
      "metadata": {
        "id": "3905214b",
        "papermill": {
          "duration": 0.023575,
          "end_time": "2025-07-27T09:38:47.386214",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.362639",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Compute Class Weights\n",
        "\n",
        "Let's compute class weights, then we can have a weighted loss function with computed class weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "2ed59ac9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:47.437817Z",
          "iopub.status.busy": "2025-07-27T09:38:47.437155Z",
          "iopub.status.idle": "2025-07-27T09:38:47.443909Z",
          "shell.execute_reply": "2025-07-27T09:38:47.443119Z"
        },
        "id": "2ed59ac9",
        "outputId": "fc0e5c12-036b-4d65-e8dc-3f5762cff7a9",
        "papermill": {
          "duration": 0.032986,
          "end_time": "2025-07-27T09:38:47.445197",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.412211",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: [0.59456265 3.14375   ]\n"
          ]
        }
      ],
      "source": [
        "# Calculate weights based on TRAINING SET only\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_df['label']),\n",
        "    y=train_df['label']\n",
        ")\n",
        "\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Convert to PyTorch tensor\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eddd6943",
      "metadata": {
        "id": "eddd6943",
        "papermill": {
          "duration": 0.026534,
          "end_time": "2025-07-27T09:38:47.498013",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.471479",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "a08b3a6e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:47.551935Z",
          "iopub.status.busy": "2025-07-27T09:38:47.551215Z",
          "iopub.status.idle": "2025-07-27T09:38:48.627458Z",
          "shell.execute_reply": "2025-07-27T09:38:48.626818Z"
        },
        "id": "a08b3a6e",
        "papermill": {
          "duration": 1.10531,
          "end_time": "2025-07-27T09:38:48.628918",
          "exception": false,
          "start_time": "2025-07-27T09:38:47.523608",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('FacebookAI/roberta-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "cde3e54c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:49.358096Z",
          "iopub.status.busy": "2025-07-27T09:38:49.357874Z",
          "iopub.status.idle": "2025-07-27T09:38:49.361799Z",
          "shell.execute_reply": "2025-07-27T09:38:49.361272Z"
        },
        "id": "cde3e54c",
        "papermill": {
          "duration": 0.030368,
          "end_time": "2025-07-27T09:38:49.362991",
          "exception": false,
          "start_time": "2025-07-27T09:38:49.332623",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def tokenize_function(batch):\n",
        "    try:\n",
        "        return tokenizer(\n",
        "            batch['text'],\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            padding=False,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Tokenization error: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "a604a71b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:49.415435Z",
          "iopub.status.busy": "2025-07-27T09:38:49.415241Z",
          "iopub.status.idle": "2025-07-27T09:38:49.447220Z",
          "shell.execute_reply": "2025-07-27T09:38:49.446711Z"
        },
        "id": "a604a71b",
        "papermill": {
          "duration": 0.060592,
          "end_time": "2025-07-27T09:38:49.448350",
          "exception": false,
          "start_time": "2025-07-27T09:38:49.387758",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# 1. Select only necessary columns\n",
        "train_df = train_df[['label', 'text']]\n",
        "val_df = val_df[['label', 'text']]\n",
        "test_df = test_df[['label', 'text']]\n",
        "\n",
        "# 2. Convert to Dataset objects (with proper validation)\n",
        "train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
        "val_dataset = Dataset.from_pandas(val_df, preserve_index=False)\n",
        "test_dataset = Dataset.from_pandas(test_df, preserve_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "e7a47a02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "99ef6e29c8c048afa7fd618b441af131",
            "d38dd0f0cef0424fb311a4a4e1327f50",
            "20796d52d1c54d349a446655d06432ac",
            "df1cdc1f6def4c039a7e67dcb7e22ed1",
            "eae288851f4d42d6a3c8eb12765dba7d",
            "85f9bcf2730548b193f2df53b6b39c3d",
            "aed33fc43bc847999e9289db055e20ce",
            "7949db41d4d944b8baf211eb0e3eafe2",
            "c882079f279c45fe8b989f17cdac2c6d",
            "c58a89ff3e654c7a955b8a070be75ed7",
            "8c0fae561c314931bfc1e60254dcaac4",
            "3e64aed5d8fe452fb45f730413f47c0a",
            "faddb02efdd44aa1b3709f4bf356d448",
            "f9a3db096d9049a296511543bf3cd705",
            "6dccaff8f27a4f4d8527089983e44c5c",
            "b2839cadf5a24cb6a8db14115774e1cf",
            "2d6c43f2016343fa86df27d93acb5dbd",
            "0c0f6aee07c44c0298eee7487e94802a",
            "82fb503359ec4594bf9128e1276cd354",
            "4cc2a6f9b1aa49bf989f46524b5584ff",
            "348f6e4159eb44f4bf46d4e913902265",
            "162addfdb7954bec914ea5929f473794",
            "e33ae1be66ab49ca84eed95b7151853b",
            "90d75a9bf3414e529241aaf22114e89f",
            "d3bdc6c3ced049bc85d6a10e7fff65ae",
            "357f93453b4e4eaa955410418ba6c4f9",
            "3171a03374fa452bb8f300f980f8f879",
            "f20335768f994e94a8dbd0b3a1846ee6",
            "7f3badfadd5846e589a1f5a94ea1692e",
            "2fb64a07ae4d4a6084f80c77ce85e6a0",
            "d2f8be1f3db7416dbf79e6f10ff45d85",
            "7f6e6bc4271044ed8585b482f635ae31",
            "1303b09724af40dc9760c8b96fff5413"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:49.499665Z",
          "iopub.status.busy": "2025-07-27T09:38:49.499204Z",
          "iopub.status.idle": "2025-07-27T09:38:53.399249Z",
          "shell.execute_reply": "2025-07-27T09:38:53.398558Z"
        },
        "id": "e7a47a02",
        "outputId": "33484782-5313-4840-ec59-c82b4ca5e928",
        "papermill": {
          "duration": 3.92703,
          "end_time": "2025-07-27T09:38:53.400685",
          "exception": false,
          "start_time": "2025-07-27T09:38:49.473655",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99ef6e29c8c048afa7fd618b441af131",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8048 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e64aed5d8fe452fb45f730413f47c0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e33ae1be66ab49ca84eed95b7151853b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 3. Apply tokenization\n",
        "tokenized_train = train_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        "    remove_columns=['text']  # Remove original text after tokenization\n",
        ")\n",
        "\n",
        "tokenized_val = val_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        "    remove_columns=['text']\n",
        ")\n",
        "\n",
        "tokenized_test = test_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=1000,\n",
        "    remove_columns=['text']\n",
        ")\n",
        "\n",
        "# 4. Sort only training set by length\n",
        "tokenized_train = tokenized_train.add_column(\n",
        "    \"length\",\n",
        "    [len(x) for x in tokenized_train[\"input_ids\"]]\n",
        ").sort(\"length\")\n",
        "\n",
        "# Final datasets\n",
        "train_dataset = tokenized_train\n",
        "val_dataset = tokenized_val\n",
        "test_dataset = tokenized_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "4d153637",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:53.457886Z",
          "iopub.status.busy": "2025-07-27T09:38:53.457603Z",
          "iopub.status.idle": "2025-07-27T09:38:53.462530Z",
          "shell.execute_reply": "2025-07-27T09:38:53.461744Z"
        },
        "id": "4d153637",
        "outputId": "7378791f-0ca1-4716-a540-f141d4df9009",
        "papermill": {
          "duration": 0.034895,
          "end_time": "2025-07-27T09:38:53.463761",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.428866",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['label', 'input_ids', 'attention_mask', 'length'],\n",
              "    num_rows: 8048\n",
              "})"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "29b8d481",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:53.518167Z",
          "iopub.status.busy": "2025-07-27T09:38:53.517865Z",
          "iopub.status.idle": "2025-07-27T09:38:53.521697Z",
          "shell.execute_reply": "2025-07-27T09:38:53.520989Z"
        },
        "id": "29b8d481",
        "papermill": {
          "duration": 0.032644,
          "end_time": "2025-07-27T09:38:53.522883",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.490239",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=tokenizer,\n",
        "    padding='longest',  # Pad to longest in batch\n",
        "    max_length=128,  # Safety cap\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "699d2d60",
      "metadata": {
        "id": "699d2d60",
        "papermill": {
          "duration": 0.025849,
          "end_time": "2025-07-27T09:38:53.575426",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.549577",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Custom Trainer to use a weighted loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "0f9b6586",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:53.628982Z",
          "iopub.status.busy": "2025-07-27T09:38:53.628392Z",
          "iopub.status.idle": "2025-07-27T09:38:53.633397Z",
          "shell.execute_reply": "2025-07-27T09:38:53.632882Z"
        },
        "id": "0f9b6586",
        "papermill": {
          "duration": 0.033273,
          "end_time": "2025-07-27T09:38:53.634576",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.601303",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights.to(kwargs['args'].device)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights, label_smoothing=0.1)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c90c4e3c",
      "metadata": {
        "id": "c90c4e3c",
        "papermill": {
          "duration": 0.025656,
          "end_time": "2025-07-27T09:38:53.687029",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.661373",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Compute metrics function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "169ab676",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:53.742268Z",
          "iopub.status.busy": "2025-07-27T09:38:53.742024Z",
          "iopub.status.idle": "2025-07-27T09:38:53.748712Z",
          "shell.execute_reply": "2025-07-27T09:38:53.747927Z"
        },
        "id": "169ab676",
        "papermill": {
          "duration": 0.036269,
          "end_time": "2025-07-27T09:38:53.749883",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.713614",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Robust metrics for imbalanced binary classification\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Essential metrics (all weighted by class support)\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(labels, predictions),\n",
        "        'f1_weighted': f1_score(labels, predictions, average='weighted'),\n",
        "        'precision_weighted': precision_score(labels, predictions, average='weighted'),\n",
        "        'recall_weighted': recall_score(labels, predictions, average='weighted'),\n",
        "    }\n",
        "\n",
        "    # Class-specific metrics\n",
        "    metrics.update({\n",
        "        # Spam class (label=1)\n",
        "        'spam_precision': precision_score(labels, predictions, pos_label=1),\n",
        "        'spam_recall': recall_score(labels, predictions, pos_label=1),\n",
        "        'spam_f1': f1_score(labels, predictions, pos_label=1),\n",
        "\n",
        "        # Ham class (label=0)\n",
        "        'ham_precision': precision_score(labels, predictions, pos_label=0),\n",
        "        'ham_recall': recall_score(labels, predictions, pos_label=0),\n",
        "    })\n",
        "\n",
        "    # Confusion matrix breakdown\n",
        "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
        "    metrics.update({\n",
        "        'confusion_matrix': {\n",
        "            'true_negatives': int(tn),  # Correct hams\n",
        "            'false_positives': int(fp), # Hams misclassified as spam (bad)\n",
        "            'false_negatives': int(fn), # Spam missed (very bad)\n",
        "            'true_positives': int(tp),  # Correct spam\n",
        "        },\n",
        "        'false_positive_rate': fp / (fp + tn),  # % of hams flagged as spam\n",
        "        'false_negative_rate': fn / (fn + tp),  # % of spam missed\n",
        "    })\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06a13ec1",
      "metadata": {
        "id": "06a13ec1",
        "papermill": {
          "duration": 0.025221,
          "end_time": "2025-07-27T09:38:53.801294",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.776073",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Optuna for Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "e4de487e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:53.854437Z",
          "iopub.status.busy": "2025-07-27T09:38:53.854155Z",
          "iopub.status.idle": "2025-07-27T09:38:53.860589Z",
          "shell.execute_reply": "2025-07-27T09:38:53.859964Z"
        },
        "id": "e4de487e",
        "papermill": {
          "duration": 0.034523,
          "end_time": "2025-07-27T09:38:53.861757",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.827234",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define objective function\n",
        "def objective(trial):\n",
        "    # 1. Get parameters\n",
        "    model_params = {\n",
        "        \"hidden_dropout_prob\": trial.suggest_float(\"hidden_dropout\", 0.1, 0.3),\n",
        "        \"attention_probs_dropout_prob\": trial.suggest_float(\"attn_dropout\", 0.1, 0.2)\n",
        "    }\n",
        "\n",
        "    training_params = {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"batch_size\", [8, 16, 32]),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_int(\"grad_accum\", 1, 4),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"epochs\", 2, 5),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup\", 0.05, 0.1)\n",
        "    }\n",
        "\n",
        "    # 2. Define the model\n",
        "    model = RobertaForSequenceClassification.from_pretrained(\n",
        "        'FacebookAI/roberta-base',\n",
        "        num_labels=2,\n",
        "        id2label={0: \"ham\", 1: \"spam\"},\n",
        "        **model_params,\n",
        "    )\n",
        "\n",
        "    # 3. Create training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='/content/temp',\n",
        "        eval_strategy=\"epoch\",  # Eval after each epoch\n",
        "        save_strategy=\"no\",  # Do not save model checkpoints\n",
        "        metric_for_best_model=\"eval_spam_f1\",\n",
        "        greater_is_better=True,\n",
        "        load_best_model_at_end=False,  # No model saved, so can't load\n",
        "        fp16=True,\n",
        "        per_device_eval_batch_size=64,\n",
        "        report_to=\"none\",\n",
        "        **training_params,\n",
        "    )\n",
        "\n",
        "    # 4. Train with class weights\n",
        "    trainer = WeightedTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        class_weights=class_weights\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    results = trainer.evaluate()\n",
        "    return results['eval_spam_f1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "1b2ecf4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T09:38:53.913526Z",
          "iopub.status.busy": "2025-07-27T09:38:53.912812Z",
          "iopub.status.idle": "2025-07-27T10:32:21.814206Z",
          "shell.execute_reply": "2025-07-27T10:32:21.813515Z"
        },
        "id": "1b2ecf4d",
        "outputId": "a8161ca2-dff1-4f1b-a5bf-7701b7394826",
        "papermill": {
          "duration": 3207.928653,
          "end_time": "2025-07-27T10:32:21.815620",
          "exception": false,
          "start_time": "2025-07-27T09:38:53.886967",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:39:00,571] A new study created in memory with name: no-name-b4e3de6a-c82f-4c0d-91b6-707bd15f2756\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1260/1260 03:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.379902</td>\n",
              "      <td>0.994783</td>\n",
              "      <td>0.994794</td>\n",
              "      <td>0.994817</td>\n",
              "      <td>0.994783</td>\n",
              "      <td>0.978417</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.983725</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.995862</td>\n",
              "      <td>{'true_negatives': 1444, 'false_positives': 6, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.004138</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.448900</td>\n",
              "      <td>0.367535</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.448900</td>\n",
              "      <td>0.364222</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.378500</td>\n",
              "      <td>0.364775</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.378500</td>\n",
              "      <td>0.364606</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:42:31,185] Trial 0 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.21689278715340385, 'attn_dropout': 0.14383645994025962, 'learning_rate': 1.0132880208140948e-05, 'weight_decay': 0.08715064383531688, 'batch_size': 16, 'grad_accum': 2, 'epochs': 5, 'warmup': 0.07679965763661617}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [378/378 01:45, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.368182</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.994220</td>\n",
              "      <td>0.994256</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.974910</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.981949</td>\n",
              "      <td>0.997925</td>\n",
              "      <td>0.995172</td>\n",
              "      <td>{'true_negatives': 1443, 'false_positives': 7, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.365320</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>{'true_negatives': 1447, 'false_positives': 3, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.362703</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:44:19,610] Trial 1 finished with value: 0.9927007299270073 and parameters: {'hidden_dropout': 0.1480404442883208, 'attn_dropout': 0.18649875667221127, 'learning_rate': 1.0657155029849667e-05, 'weight_decay': 0.05994556826881249, 'batch_size': 16, 'grad_accum': 4, 'epochs': 3, 'warmup': 0.09463013452591838}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='756' max='756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [756/756 02:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.365707</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997674</td>\n",
              "      <td>0.997688</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.985455</td>\n",
              "      <td>0.992674</td>\n",
              "      <td>0.997249</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 4, 'true_positives': 271}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.444300</td>\n",
              "      <td>0.364304</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.444300</td>\n",
              "      <td>0.362261</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:47:16,768] Trial 2 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.17430424071123318, 'attn_dropout': 0.17486340789094143, 'learning_rate': 3.0259528495958154e-05, 'weight_decay': 0.03545094880273373, 'batch_size': 8, 'grad_accum': 4, 'epochs': 3, 'warmup': 0.08046089527397718}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [504/504 01:23, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.369100</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.995945</td>\n",
              "      <td>0.995949</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.987296</td>\n",
              "      <td>0.997930</td>\n",
              "      <td>0.997241</td>\n",
              "      <td>{'true_negatives': 1446, 'false_positives': 4, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.419200</td>\n",
              "      <td>0.364971</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:48:42,938] Trial 3 finished with value: 0.9908925318761385 and parameters: {'hidden_dropout': 0.22058295420791113, 'attn_dropout': 0.16715549322685241, 'learning_rate': 4.381372865646831e-05, 'weight_decay': 0.07550381485924254, 'batch_size': 16, 'grad_accum': 2, 'epochs': 2, 'warmup': 0.08038401336945174}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [378/378 01:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.375385</td>\n",
              "      <td>0.994783</td>\n",
              "      <td>0.994794</td>\n",
              "      <td>0.994817</td>\n",
              "      <td>0.994783</td>\n",
              "      <td>0.978417</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.983725</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.995862</td>\n",
              "      <td>{'true_negatives': 1444, 'false_positives': 6, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.004138</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.373572</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.994220</td>\n",
              "      <td>0.994256</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.974910</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.981949</td>\n",
              "      <td>0.997925</td>\n",
              "      <td>0.995172</td>\n",
              "      <td>{'true_negatives': 1443, 'false_positives': 7, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.367993</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>{'true_negatives': 1447, 'false_positives': 3, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:50:19,069] Trial 4 finished with value: 0.9890909090909091 and parameters: {'hidden_dropout': 0.22213367967113973, 'attn_dropout': 0.17937624368114935, 'learning_rate': 1.0326994907672805e-05, 'weight_decay': 0.0664938430227374, 'batch_size': 32, 'grad_accum': 2, 'epochs': 3, 'warmup': 0.0965507717298859}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2012' max='2012' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2012/2012 03:33, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.478000</td>\n",
              "      <td>0.371950</td>\n",
              "      <td>0.993043</td>\n",
              "      <td>0.993074</td>\n",
              "      <td>0.993148</td>\n",
              "      <td>0.993043</td>\n",
              "      <td>0.967972</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.978417</td>\n",
              "      <td>0.997922</td>\n",
              "      <td>0.993793</td>\n",
              "      <td>{'true_negatives': 1441, 'false_positives': 9, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.006207</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.393500</td>\n",
              "      <td>0.367080</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.385800</td>\n",
              "      <td>0.367547</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.380300</td>\n",
              "      <td>0.367708</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:53:55,726] Trial 5 finished with value: 0.9908925318761385 and parameters: {'hidden_dropout': 0.24454173161415851, 'attn_dropout': 0.1842374659555925, 'learning_rate': 1.25469814058172e-05, 'weight_decay': 0.07242820599343032, 'batch_size': 16, 'grad_accum': 1, 'epochs': 4, 'warmup': 0.07263330201368474}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1680' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1680/1680 05:10, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.370314</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.994220</td>\n",
              "      <td>0.994256</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.974910</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.981949</td>\n",
              "      <td>0.997925</td>\n",
              "      <td>0.995172</td>\n",
              "      <td>{'true_negatives': 1443, 'false_positives': 7, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.486200</td>\n",
              "      <td>0.367345</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.995945</td>\n",
              "      <td>0.995949</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.987296</td>\n",
              "      <td>0.997930</td>\n",
              "      <td>0.997241</td>\n",
              "      <td>{'true_negatives': 1446, 'false_positives': 4, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.368668</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.365388</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.407400</td>\n",
              "      <td>0.365761</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 14:59:09,459] Trial 6 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.24427312933207648, 'attn_dropout': 0.12488984313732142, 'learning_rate': 1.2806499936541583e-05, 'weight_decay': 0.05390968412164776, 'batch_size': 8, 'grad_accum': 3, 'epochs': 5, 'warmup': 0.08996422315336924}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2012' max='2012' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2012/2012 04:41, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.465000</td>\n",
              "      <td>0.367578</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996511</td>\n",
              "      <td>0.996521</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996310</td>\n",
              "      <td>0.981818</td>\n",
              "      <td>0.989011</td>\n",
              "      <td>0.996561</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 5, 'true_positives': 270}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.018182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.409300</td>\n",
              "      <td>0.362333</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.400200</td>\n",
              "      <td>0.360196</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999421</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996364</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.999311</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 1, 'true_positives': 274}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.399200</td>\n",
              "      <td>0.359827</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:03:54,332] Trial 7 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.1182990145647799, 'attn_dropout': 0.18366085746649624, 'learning_rate': 2.2998754919385365e-05, 'weight_decay': 0.06562318977441643, 'batch_size': 8, 'grad_accum': 2, 'epochs': 4, 'warmup': 0.06401116443081406}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1344' max='1344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1344/1344 04:08, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.373234</td>\n",
              "      <td>0.990725</td>\n",
              "      <td>0.990791</td>\n",
              "      <td>0.990977</td>\n",
              "      <td>0.990725</td>\n",
              "      <td>0.954386</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.997917</td>\n",
              "      <td>0.991034</td>\n",
              "      <td>{'true_negatives': 1437, 'false_positives': 13, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.008966</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.475800</td>\n",
              "      <td>0.366890</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.369690</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.369351</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.995945</td>\n",
              "      <td>0.995949</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.987296</td>\n",
              "      <td>0.997930</td>\n",
              "      <td>0.997241</td>\n",
              "      <td>{'true_negatives': 1446, 'false_positives': 4, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:08:05,495] Trial 8 finished with value: 0.9872958257713249 and parameters: {'hidden_dropout': 0.2994047420131315, 'attn_dropout': 0.1475892987570298, 'learning_rate': 2.1014975780945237e-05, 'weight_decay': 0.04383897953497976, 'batch_size': 8, 'grad_accum': 3, 'epochs': 4, 'warmup': 0.05483606785220338}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1008' max='1008' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1008/1008 03:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.368397</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.995939</td>\n",
              "      <td>0.995937</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.989051</td>\n",
              "      <td>0.985455</td>\n",
              "      <td>0.987250</td>\n",
              "      <td>0.997243</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>{'true_negatives': 1447, 'false_positives': 3, 'false_negatives': 4, 'true_positives': 271}</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.014545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.460800</td>\n",
              "      <td>0.366953</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>{'true_negatives': 1447, 'false_positives': 3, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.407800</td>\n",
              "      <td>0.366008</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:11:14,449] Trial 9 finished with value: 0.9927007299270073 and parameters: {'hidden_dropout': 0.24752878173118412, 'attn_dropout': 0.15000267113966434, 'learning_rate': 3.8606461046619945e-05, 'weight_decay': 0.08397334663724046, 'batch_size': 8, 'grad_accum': 3, 'epochs': 3, 'warmup': 0.09650076990760954}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1260/1260 03:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.394269</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.994220</td>\n",
              "      <td>0.994256</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.974910</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.981949</td>\n",
              "      <td>0.997925</td>\n",
              "      <td>0.995172</td>\n",
              "      <td>{'true_negatives': 1443, 'false_positives': 7, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.442400</td>\n",
              "      <td>0.377604</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>{'true_negatives': 1447, 'false_positives': 3, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.442400</td>\n",
              "      <td>0.372035</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.368678</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.368713</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:14:21,074] Trial 10 finished with value: 0.9927007299270073 and parameters: {'hidden_dropout': 0.2971687991745248, 'attn_dropout': 0.1003706024388206, 'learning_rate': 1.776284342026747e-05, 'weight_decay': 0.09945202736811593, 'batch_size': 32, 'grad_accum': 1, 'epochs': 5, 'warmup': 0.06831443185420003}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [252/252 01:10, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.367000</td>\n",
              "      <td>0.993623</td>\n",
              "      <td>0.993637</td>\n",
              "      <td>0.993662</td>\n",
              "      <td>0.993623</td>\n",
              "      <td>0.974820</td>\n",
              "      <td>0.985455</td>\n",
              "      <td>0.980108</td>\n",
              "      <td>0.997236</td>\n",
              "      <td>0.995172</td>\n",
              "      <td>{'true_negatives': 1443, 'false_positives': 7, 'false_negatives': 4, 'true_positives': 271}</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>0.014545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.362274</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:15:34,389] Trial 11 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.17414652000461786, 'attn_dropout': 0.1538790958610167, 'learning_rate': 3.171142051142759e-05, 'weight_decay': 0.015479389711920016, 'batch_size': 16, 'grad_accum': 4, 'epochs': 2, 'warmup': 0.08124663804122526}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1260/1260 04:50, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.365489</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.453400</td>\n",
              "      <td>0.365479</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.453400</td>\n",
              "      <td>0.365059</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.399300</td>\n",
              "      <td>0.362740</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.399300</td>\n",
              "      <td>0.361752</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:20:27,600] Trial 12 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.1795716100204695, 'attn_dropout': 0.13132988960126996, 'learning_rate': 2.880418666012935e-05, 'weight_decay': 0.028078550923748904, 'batch_size': 8, 'grad_accum': 4, 'epochs': 5, 'warmup': 0.08271383376080124}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='756' max='756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [756/756 02:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.366577</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.426600</td>\n",
              "      <td>0.363548</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.426600</td>\n",
              "      <td>0.363276</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:22:34,272] Trial 13 finished with value: 0.9927007299270073 and parameters: {'hidden_dropout': 0.19093890700567373, 'attn_dropout': 0.16808457130865542, 'learning_rate': 1.6436495216096635e-05, 'weight_decay': 0.033963114646416395, 'batch_size': 16, 'grad_accum': 2, 'epochs': 3, 'warmup': 0.060504341339445114}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [336/336 01:56, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.375289</td>\n",
              "      <td>0.980870</td>\n",
              "      <td>0.981227</td>\n",
              "      <td>0.982391</td>\n",
              "      <td>0.980870</td>\n",
              "      <td>0.900662</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.942808</td>\n",
              "      <td>0.997892</td>\n",
              "      <td>0.979310</td>\n",
              "      <td>{'true_negatives': 1420, 'false_positives': 30, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.020690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.368483</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.362846</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.362411</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:24:33,621] Trial 14 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.14490092573592372, 'attn_dropout': 0.19616914483729808, 'learning_rate': 2.627474861967506e-05, 'weight_decay': 0.00880668321754613, 'batch_size': 32, 'grad_accum': 3, 'epochs': 4, 'warmup': 0.0753336937711104}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2012' max='2012' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2012/2012 03:15, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.436300</td>\n",
              "      <td>0.368967</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996506</td>\n",
              "      <td>0.996536</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.978182</td>\n",
              "      <td>0.988971</td>\n",
              "      <td>0.995879</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 6, 'true_positives': 269}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.021818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.408900</td>\n",
              "      <td>0.363353</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:27:51,621] Trial 15 finished with value: 0.9927007299270073 and parameters: {'hidden_dropout': 0.10431628681724006, 'attn_dropout': 0.13259576169651766, 'learning_rate': 3.444853048274258e-05, 'weight_decay': 0.0951093669814113, 'batch_size': 8, 'grad_accum': 1, 'epochs': 2, 'warmup': 0.08728867482369412}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 02:56, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.368508</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.995945</td>\n",
              "      <td>0.995949</td>\n",
              "      <td>0.995942</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.987296</td>\n",
              "      <td>0.997930</td>\n",
              "      <td>0.997241</td>\n",
              "      <td>{'true_negatives': 1446, 'false_positives': 4, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002759</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.372258</td>\n",
              "      <td>0.993043</td>\n",
              "      <td>0.993074</td>\n",
              "      <td>0.993148</td>\n",
              "      <td>0.993043</td>\n",
              "      <td>0.967972</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.978417</td>\n",
              "      <td>0.997922</td>\n",
              "      <td>0.993793</td>\n",
              "      <td>{'true_negatives': 1441, 'false_positives': 9, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.006207</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.367715</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.407000</td>\n",
              "      <td>0.362125</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998262</td>\n",
              "      <td>0.998265</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.992754</td>\n",
              "      <td>0.996364</td>\n",
              "      <td>0.994555</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 1, 'true_positives': 274}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.003636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.407000</td>\n",
              "      <td>0.361514</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:30:50,940] Trial 16 finished with value: 0.9927007299270073 and parameters: {'hidden_dropout': 0.21001997086898685, 'attn_dropout': 0.16388016595737454, 'learning_rate': 4.969623025779783e-05, 'weight_decay': 0.04348274241443987, 'batch_size': 16, 'grad_accum': 4, 'epochs': 5, 'warmup': 0.0727689942522188}. Best is trial 0 with value: 0.9945155393053017.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='672' max='672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [672/672 02:28, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.365556</td>\n",
              "      <td>0.995362</td>\n",
              "      <td>0.995369</td>\n",
              "      <td>0.995381</td>\n",
              "      <td>0.995362</td>\n",
              "      <td>0.981949</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.985507</td>\n",
              "      <td>0.997928</td>\n",
              "      <td>0.996552</td>\n",
              "      <td>{'true_negatives': 1445, 'false_positives': 5, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.003448</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.361732</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.360620</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.411900</td>\n",
              "      <td>0.360065</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999421</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996364</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.999311</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 1, 'true_positives': 274}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:33:23,143] Trial 17 finished with value: 0.9981785063752276 and parameters: {'hidden_dropout': 0.1606555688588448, 'attn_dropout': 0.11569233484896506, 'learning_rate': 1.668858287424864e-05, 'weight_decay': 0.023492855879941946, 'batch_size': 16, 'grad_accum': 3, 'epochs': 4, 'warmup': 0.05016957598729442}. Best is trial 17 with value: 0.9981785063752276.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1260/1260 03:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.364940</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997674</td>\n",
              "      <td>0.997688</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.985455</td>\n",
              "      <td>0.992674</td>\n",
              "      <td>0.997249</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 4, 'true_positives': 271}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.363233</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.362602</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.373900</td>\n",
              "      <td>0.362709</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.373900</td>\n",
              "      <td>0.362506</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:36:52,459] Trial 18 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.15536877935041063, 'attn_dropout': 0.10625502371804557, 'learning_rate': 1.557688365134015e-05, 'weight_decay': 0.016413971917506216, 'batch_size': 16, 'grad_accum': 2, 'epochs': 5, 'warmup': 0.05015713570799631}. Best is trial 17 with value: 0.9981785063752276.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='672' max='672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [672/672 02:28, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.365485</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.362225</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.414500</td>\n",
              "      <td>0.360734</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.414500</td>\n",
              "      <td>0.361203</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:39:24,392] Trial 19 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.13205310437109463, 'attn_dropout': 0.11568852878143379, 'learning_rate': 1.332346980718608e-05, 'weight_decay': 0.00032023490707625696, 'batch_size': 16, 'grad_accum': 3, 'epochs': 4, 'warmup': 0.06007645775179364}. Best is trial 17 with value: 0.9981785063752276.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1260/1260 03:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.378928</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.994211</td>\n",
              "      <td>0.994225</td>\n",
              "      <td>0.994203</td>\n",
              "      <td>0.978339</td>\n",
              "      <td>0.985455</td>\n",
              "      <td>0.981884</td>\n",
              "      <td>0.997238</td>\n",
              "      <td>0.995862</td>\n",
              "      <td>{'true_negatives': 1444, 'false_positives': 6, 'false_negatives': 4, 'true_positives': 271}</td>\n",
              "      <td>0.004138</td>\n",
              "      <td>0.014545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.442400</td>\n",
              "      <td>0.366201</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997674</td>\n",
              "      <td>0.997688</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.985455</td>\n",
              "      <td>0.992674</td>\n",
              "      <td>0.997249</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 4, 'true_positives': 271}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.442400</td>\n",
              "      <td>0.367508</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>0.367563</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.383000</td>\n",
              "      <td>0.366467</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:42:54,265] Trial 20 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.2758078555593893, 'attn_dropout': 0.14033587048129717, 'learning_rate': 1.957530810523826e-05, 'weight_decay': 0.08501877126979615, 'batch_size': 16, 'grad_accum': 2, 'epochs': 5, 'warmup': 0.0671771612153561}. Best is trial 17 with value: 0.9981785063752276.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [378/378 01:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.365606</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.364299</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.362747</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:44:44,054] Trial 21 finished with value: 0.9908925318761385 and parameters: {'hidden_dropout': 0.17403206711264468, 'attn_dropout': 0.11419192952639406, 'learning_rate': 2.5324414016241253e-05, 'weight_decay': 0.026959388395653833, 'batch_size': 16, 'grad_accum': 4, 'epochs': 3, 'warmup': 0.07593856127843925}. Best is trial 17 with value: 0.9981785063752276.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1344' max='1344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1344/1344 04:09, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.366726</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996517</td>\n",
              "      <td>0.996516</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.992674</td>\n",
              "      <td>0.985455</td>\n",
              "      <td>0.989051</td>\n",
              "      <td>0.997245</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 4, 'true_positives': 271}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.014545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.470700</td>\n",
              "      <td>0.364513</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997099</td>\n",
              "      <td>0.997098</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.990893</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.998621</td>\n",
              "      <td>{'true_negatives': 1448, 'false_positives': 2, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.407300</td>\n",
              "      <td>0.365183</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.407300</td>\n",
              "      <td>0.364609</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:48:56,937] Trial 22 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.19950491810744678, 'attn_dropout': 0.14012949110308842, 'learning_rate': 1.4671110358464341e-05, 'weight_decay': 0.03625344643614956, 'batch_size': 8, 'grad_accum': 3, 'epochs': 4, 'warmup': 0.08630810144198271}. Best is trial 17 with value: 0.9981785063752276.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [189/189 01:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.374338</td>\n",
              "      <td>0.986087</td>\n",
              "      <td>0.986264</td>\n",
              "      <td>0.986813</td>\n",
              "      <td>0.986087</td>\n",
              "      <td>0.928328</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.957746</td>\n",
              "      <td>0.997905</td>\n",
              "      <td>0.985517</td>\n",
              "      <td>{'true_negatives': 1429, 'false_positives': 21, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.014483</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.364904</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.996522</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>0.997931</td>\n",
              "      <td>{'true_negatives': 1447, 'false_positives': 3, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.363956</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:50:24,248] Trial 23 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.15972607201336492, 'attn_dropout': 0.15936728629797942, 'learning_rate': 1.9468927850274166e-05, 'weight_decay': 0.02342993982514935, 'batch_size': 32, 'grad_accum': 4, 'epochs': 3, 'warmup': 0.0788937533440023}. Best is trial 17 with value: 0.9981785063752276.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='672' max='672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [672/672 02:28, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.369899</td>\n",
              "      <td>0.992464</td>\n",
              "      <td>0.992502</td>\n",
              "      <td>0.992599</td>\n",
              "      <td>0.992464</td>\n",
              "      <td>0.964539</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.976661</td>\n",
              "      <td>0.997921</td>\n",
              "      <td>0.993103</td>\n",
              "      <td>{'true_negatives': 1440, 'false_positives': 10, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.006897</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.371020</td>\n",
              "      <td>0.994783</td>\n",
              "      <td>0.994794</td>\n",
              "      <td>0.994817</td>\n",
              "      <td>0.994783</td>\n",
              "      <td>0.978417</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.983725</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.995862</td>\n",
              "      <td>{'true_negatives': 1444, 'false_positives': 6, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.004138</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.424600</td>\n",
              "      <td>0.364787</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.424600</td>\n",
              "      <td>0.364499</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>0.998257</td>\n",
              "      <td>0.998264</td>\n",
              "      <td>0.998261</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.994516</td>\n",
              "      <td>0.997935</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-02 15:52:56,250] Trial 24 finished with value: 0.9945155393053017 and parameters: {'hidden_dropout': 0.1833352884334686, 'attn_dropout': 0.17490599131254286, 'learning_rate': 1.117228715341501e-05, 'weight_decay': 0.04857105401601267, 'batch_size': 16, 'grad_accum': 3, 'epochs': 4, 'warmup': 0.06895734412410115}. Best is trial 17 with value: 0.9981785063752276.\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=25, timeout=2.5*60*60)\n",
        "\n",
        "best_params = study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "PunAD3Nof80S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PunAD3Nof80S",
        "outputId": "67e23b35-0ca6-4c78-b1f3-f6f401875399"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hidden_dropout': 0.1606555688588448,\n",
              " 'attn_dropout': 0.11569233484896506,\n",
              " 'learning_rate': 1.668858287424864e-05,\n",
              " 'weight_decay': 0.023492855879941946,\n",
              " 'batch_size': 16,\n",
              " 'grad_accum': 3,\n",
              " 'epochs': 4,\n",
              " 'warmup': 0.05016957598729442}"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85a4fd97",
      "metadata": {
        "id": "85a4fd97",
        "papermill": {
          "duration": 0.028597,
          "end_time": "2025-07-27T10:32:21.876224",
          "exception": false,
          "start_time": "2025-07-27T10:32:21.847627",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Train the model with best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "4a48f039",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T10:32:21.943405Z",
          "iopub.status.busy": "2025-07-27T10:32:21.943124Z",
          "iopub.status.idle": "2025-07-27T10:32:21.947284Z",
          "shell.execute_reply": "2025-07-27T10:32:21.946687Z"
        },
        "id": "4a48f039",
        "papermill": {
          "duration": 0.034924,
          "end_time": "2025-07-27T10:32:21.948240",
          "exception": false,
          "start_time": "2025-07-27T10:32:21.913316",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "best_model_params = {\n",
        "        \"hidden_dropout_prob\": best_params[\"hidden_dropout\"],\n",
        "        \"attention_probs_dropout_prob\": best_params[\"attn_dropout\"]\n",
        "}\n",
        "\n",
        "best_training_params = {\n",
        "        \"learning_rate\": best_params[\"learning_rate\"],\n",
        "        \"weight_decay\": best_params[\"weight_decay\"],\n",
        "        \"per_device_train_batch_size\": best_params[\"batch_size\"],\n",
        "        \"gradient_accumulation_steps\": best_params[\"grad_accum\"],\n",
        "        \"num_train_epochs\": best_params[\"epochs\"],\n",
        "        \"warmup_ratio\": best_params[\"warmup\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "35d2a98e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T10:32:22.006197Z",
          "iopub.status.busy": "2025-07-27T10:32:22.005986Z",
          "iopub.status.idle": "2025-07-27T10:32:22.293205Z",
          "shell.execute_reply": "2025-07-27T10:32:22.292453Z"
        },
        "id": "35d2a98e",
        "outputId": "7394e11e-e359-494e-db09-f569b428727a",
        "papermill": {
          "duration": 0.317412,
          "end_time": "2025-07-27T10:32:22.294452",
          "exception": false,
          "start_time": "2025-07-27T10:32:21.977040",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "            'FacebookAI/roberta-base',\n",
        "            num_labels=2,\n",
        "            id2label={0: \"ham\", 1: \"spam\"},\n",
        "            **best_model_params\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "1a4f9a65",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T10:32:22.354186Z",
          "iopub.status.busy": "2025-07-27T10:32:22.353921Z",
          "iopub.status.idle": "2025-07-27T10:32:22.387318Z",
          "shell.execute_reply": "2025-07-27T10:32:22.386322Z"
        },
        "id": "1a4f9a65",
        "papermill": {
          "duration": 0.064447,
          "end_time": "2025-07-27T10:32:22.388583",
          "exception": false,
          "start_time": "2025-07-27T10:32:22.324136",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    metric_for_best_model=\"eval_spam_f1\",\n",
        "    greater_is_better=True,\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True,\n",
        "    per_device_eval_batch_size=64,\n",
        "    report_to=\"none\",\n",
        "    logging_steps=50,\n",
        "    logging_dir='/content/logs',\n",
        "    save_total_limit=2,\n",
        "    **best_training_params,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "8faebfd5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T10:32:22.448794Z",
          "iopub.status.busy": "2025-07-27T10:32:22.448539Z",
          "iopub.status.idle": "2025-07-27T10:32:22.640940Z",
          "shell.execute_reply": "2025-07-27T10:32:22.640374Z"
        },
        "id": "8faebfd5",
        "papermill": {
          "duration": 0.223617,
          "end_time": "2025-07-27T10:32:22.642214",
          "exception": false,
          "start_time": "2025-07-27T10:32:22.418597",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    class_weights=class_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "bf30334c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T10:32:22.702522Z",
          "iopub.status.busy": "2025-07-27T10:32:22.702268Z",
          "iopub.status.idle": "2025-07-27T10:37:30.005032Z",
          "shell.execute_reply": "2025-07-27T10:37:30.004381Z"
        },
        "id": "bf30334c",
        "outputId": "9b2324c5-0831-4af4-c403-a2625f0c76ad",
        "papermill": {
          "duration": 307.333546,
          "end_time": "2025-07-27T10:37:30.006273",
          "exception": false,
          "start_time": "2025-07-27T10:32:22.672727",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='672' max='672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [672/672 03:24, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Spam Precision</th>\n",
              "      <th>Spam Recall</th>\n",
              "      <th>Spam F1</th>\n",
              "      <th>Ham Precision</th>\n",
              "      <th>Ham Recall</th>\n",
              "      <th>Confusion Matrix</th>\n",
              "      <th>False Positive Rate</th>\n",
              "      <th>False Negative Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.378200</td>\n",
              "      <td>0.367310</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>0.997091</td>\n",
              "      <td>0.997111</td>\n",
              "      <td>0.997101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.981818</td>\n",
              "      <td>0.990826</td>\n",
              "      <td>0.996564</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 5, 'true_positives': 270}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.387600</td>\n",
              "      <td>0.361967</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.997678</td>\n",
              "      <td>0.997679</td>\n",
              "      <td>0.997681</td>\n",
              "      <td>0.996337</td>\n",
              "      <td>0.989091</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.997934</td>\n",
              "      <td>0.999310</td>\n",
              "      <td>{'true_negatives': 1449, 'false_positives': 1, 'false_negatives': 3, 'true_positives': 272}</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.010909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.372800</td>\n",
              "      <td>0.359235</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999421</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996364</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.999311</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 1, 'true_positives': 274}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.364200</td>\n",
              "      <td>0.359944</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>0.999421</td>\n",
              "      <td>0.999420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996364</td>\n",
              "      <td>0.998179</td>\n",
              "      <td>0.999311</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>{'true_negatives': 1450, 'false_positives': 0, 'false_negatives': 1, 'true_positives': 274}</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=672, training_loss=0.37428171152160283, metrics={'train_runtime': 204.3899, 'train_samples_per_second': 157.503, 'train_steps_per_second': 3.288, 'total_flos': 997462233090240.0, 'train_loss': 0.37428171152160283, 'epoch': 4.0})"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Start training (with class weights)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d68c9fe",
      "metadata": {
        "id": "9d68c9fe",
        "papermill": {
          "duration": 0.028771,
          "end_time": "2025-07-27T10:37:30.065395",
          "exception": false,
          "start_time": "2025-07-27T10:37:30.036624",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "a0146281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T10:37:30.123366Z",
          "iopub.status.busy": "2025-07-27T10:37:30.123123Z",
          "iopub.status.idle": "2025-07-27T10:37:31.472222Z",
          "shell.execute_reply": "2025-07-27T10:37:31.471457Z"
        },
        "id": "a0146281",
        "outputId": "4c1ede28-fd16-4216-8661-47127156eb6d",
        "papermill": {
          "duration": 1.379737,
          "end_time": "2025-07-27T10:37:31.473478",
          "exception": false,
          "start_time": "2025-07-27T10:37:30.093741",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('best_spam_classifier_tokenizer/tokenizer_config.json',\n",
              " 'best_spam_classifier_tokenizer/special_tokens_map.json',\n",
              " 'best_spam_classifier_tokenizer/vocab.json',\n",
              " 'best_spam_classifier_tokenizer/merges.txt',\n",
              " 'best_spam_classifier_tokenizer/added_tokens.json')"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the best model (based on eval_spam_f1)\n",
        "trainer.save_model(\"best_spam_classifier_model\")\n",
        "tokenizer.save_pretrained(\"best_spam_classifier_tokenizer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a4b16a",
      "metadata": {
        "id": "70a4b16a",
        "papermill": {
          "duration": 0.029006,
          "end_time": "2025-07-27T10:37:31.532594",
          "exception": false,
          "start_time": "2025-07-27T10:37:31.503588",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "1d6ba159",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T10:37:31.592095Z",
          "iopub.status.busy": "2025-07-27T10:37:31.591818Z",
          "iopub.status.idle": "2025-07-27T10:37:33.266492Z",
          "shell.execute_reply": "2025-07-27T10:37:33.265927Z"
        },
        "id": "1d6ba159",
        "outputId": "9f97672d-99a8-4d9e-8061-01d1dd9b6d0a",
        "papermill": {
          "duration": 1.705683,
          "end_time": "2025-07-27T10:37:33.267612",
          "exception": false,
          "start_time": "2025-07-27T10:37:31.561929",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate on test set\n",
        "test_results = trainer.evaluate(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "80776e90",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-07-27T10:37:33.328713Z",
          "iopub.status.busy": "2025-07-27T10:37:33.328213Z",
          "iopub.status.idle": "2025-07-27T10:37:33.333527Z",
          "shell.execute_reply": "2025-07-27T10:37:33.332981Z"
        },
        "id": "80776e90",
        "papermill": {
          "duration": 0.036168,
          "end_time": "2025-07-27T10:37:33.334512",
          "exception": false,
          "start_time": "2025-07-27T10:37:33.298344",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def print_metrics(metrics):\n",
        "    \"\"\"Prints classification metrics in a human-readable format\"\"\"\n",
        "    print(\"\\nClassification Report\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Overall Performance\n",
        "    print(\"\\nOverall Metrics:\")\n",
        "    print(f\"  Accuracy:           {metrics['eval_accuracy']:.2%}\")\n",
        "    print(f\"  Weighted F1:        {metrics['eval_f1_weighted']:.4f}\")\n",
        "    print(f\"  Weighted Precision: {metrics['eval_precision_weighted']:.4f}\")\n",
        "    print(f\"  Weighted Recall:    {metrics['eval_recall_weighted']:.4f}\")\n",
        "\n",
        "    # Spam-Specific Performance\n",
        "    print(\"\\nSpam Detection:\")\n",
        "    print(f\"  Precision: {metrics['eval_spam_precision']:.2%} (False alarm rate)\")\n",
        "    print(f\"  Recall:    {metrics['eval_spam_recall']:.2%} (Spam caught)\")\n",
        "    print(f\"  F1:        {metrics['eval_spam_f1']:.4f} (Balance)\")\n",
        "    print(f\"  Miss Rate: {metrics['eval_false_negative_rate']:.2%} (Spam missed)\")\n",
        "\n",
        "    # Ham-Specific Performance\n",
        "    print(\"\\nHam Detection:\")\n",
        "    print(f\"  Precision: {metrics['eval_ham_precision']:.2%}\")\n",
        "    print(f\"  Recall:    {metrics['eval_ham_recall']:.2%}\")\n",
        "    print(f\"  FP Rate:   {metrics['eval_false_positive_rate']:.2%} (Ham flagged as spam)\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = metrics['eval_confusion_matrix']\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(f\"          | Predicted Ham | Predicted Spam\")\n",
        "    print(f\"----------|---------------|---------------\")\n",
        "    print(f\"Actual Ham| {cm['true_negatives']:^13} | {cm['false_positives']:^13}\")\n",
        "    print(f\"Actual Spam| {cm['false_negatives']:^13} | {cm['true_positives']:^13}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "995b2448",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-07-27T10:37:33.396496Z",
          "iopub.status.busy": "2025-07-27T10:37:33.396062Z",
          "iopub.status.idle": "2025-07-27T10:37:33.399987Z",
          "shell.execute_reply": "2025-07-27T10:37:33.399129Z"
        },
        "id": "995b2448",
        "outputId": "a3f07702-e320-481a-e13a-a03f115d6382",
        "papermill": {
          "duration": 0.03568,
          "end_time": "2025-07-27T10:37:33.401189",
          "exception": false,
          "start_time": "2025-07-27T10:37:33.365509",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report\n",
            "========================================\n",
            "\n",
            "Overall Metrics:\n",
            "  Accuracy:           99.88%\n",
            "  Weighted F1:        0.9988\n",
            "  Weighted Precision: 0.9988\n",
            "  Weighted Recall:    0.9988\n",
            "\n",
            "Spam Detection:\n",
            "  Precision: 100.00% (False alarm rate)\n",
            "  Recall:    99.27% (Spam caught)\n",
            "  F1:        0.9963 (Balance)\n",
            "  Miss Rate: 0.73% (Spam missed)\n",
            "\n",
            "Ham Detection:\n",
            "  Precision: 99.86%\n",
            "  Recall:    100.00%\n",
            "  FP Rate:   0.00% (Ham flagged as spam)\n",
            "\n",
            "Confusion Matrix:\n",
            "          | Predicted Ham | Predicted Spam\n",
            "----------|---------------|---------------\n",
            "Actual Ham|     1451      |       0      \n",
            "Actual Spam|       2       |      272     \n"
          ]
        }
      ],
      "source": [
        "print_metrics(test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fbbfc37-7574-4fe6-bf2f-1201aa94c0d9",
      "metadata": {
        "id": "7fbbfc37-7574-4fe6-bf2f-1201aa94c0d9"
      },
      "source": [
        "---\n",
        "\n",
        "## Model Acceptance Summary\n",
        "\n",
        "As evaluated on the test set:\n",
        "\n",
        "- **F1-score for the `spam` class**: `0.9963`\n",
        "\n",
        "This exceeds our predefined acceptance threshold of **0.95**, indicating that the model performs reliably in identifying spam messages with a strong balance between precision and recall.\n",
        "\n",
        "> âœ… **Therefore, this model is accepted for deployment and will be integrated into Amy â€” our intelligent Discord bot.**\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 483,
          "sourceId": 982,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3669.821405,
      "end_time": "2025-07-27T10:37:37.163752",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-07-27T09:36:27.342347",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state":{},
        "0c0f6aee07c44c0298eee7487e94802a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1303b09724af40dc9760c8b96fff5413": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "162addfdb7954bec914ea5929f473794": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20796d52d1c54d349a446655d06432ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7949db41d4d944b8baf211eb0e3eafe2",
            "max": 8048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c882079f279c45fe8b989f17cdac2c6d",
            "value": 8048
          }
        },
        "2d6c43f2016343fa86df27d93acb5dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb64a07ae4d4a6084f80c77ce85e6a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3171a03374fa452bb8f300f980f8f879": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348f6e4159eb44f4bf46d4e913902265": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357f93453b4e4eaa955410418ba6c4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f6e6bc4271044ed8585b482f635ae31",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1303b09724af40dc9760c8b96fff5413",
            "value": "â€‡1725/1725â€‡[00:00&lt;00:00,â€‡3616.33â€‡examples/s]"
          }
        },
        "3e64aed5d8fe452fb45f730413f47c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_faddb02efdd44aa1b3709f4bf356d448",
              "IPY_MODEL_f9a3db096d9049a296511543bf3cd705",
              "IPY_MODEL_6dccaff8f27a4f4d8527089983e44c5c"
            ],
            "layout": "IPY_MODEL_b2839cadf5a24cb6a8db14115774e1cf"
          }
        },
        "4cc2a6f9b1aa49bf989f46524b5584ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dccaff8f27a4f4d8527089983e44c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348f6e4159eb44f4bf46d4e913902265",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_162addfdb7954bec914ea5929f473794",
            "value": "â€‡1725/1725â€‡[00:00&lt;00:00,â€‡2199.91â€‡examples/s]"
          }
        },
        "7949db41d4d944b8baf211eb0e3eafe2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3badfadd5846e589a1f5a94ea1692e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f6e6bc4271044ed8585b482f635ae31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82fb503359ec4594bf9128e1276cd354": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f9bcf2730548b193f2df53b6b39c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c0fae561c314931bfc1e60254dcaac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90d75a9bf3414e529241aaf22114e89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f20335768f994e94a8dbd0b3a1846ee6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7f3badfadd5846e589a1f5a94ea1692e",
            "value": "Map:â€‡100%"
          }
        },
        "99ef6e29c8c048afa7fd618b441af131": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d38dd0f0cef0424fb311a4a4e1327f50",
              "IPY_MODEL_20796d52d1c54d349a446655d06432ac",
              "IPY_MODEL_df1cdc1f6def4c039a7e67dcb7e22ed1"
            ],
            "layout": "IPY_MODEL_eae288851f4d42d6a3c8eb12765dba7d"
          }
        },
        "aed33fc43bc847999e9289db055e20ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2839cadf5a24cb6a8db14115774e1cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58a89ff3e654c7a955b8a070be75ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c882079f279c45fe8b989f17cdac2c6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2f8be1f3db7416dbf79e6f10ff45d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d38dd0f0cef0424fb311a4a4e1327f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85f9bcf2730548b193f2df53b6b39c3d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aed33fc43bc847999e9289db055e20ce",
            "value": "Map:â€‡100%"
          }
        },
        "d3bdc6c3ced049bc85d6a10e7fff65ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb64a07ae4d4a6084f80c77ce85e6a0",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2f8be1f3db7416dbf79e6f10ff45d85",
            "value": 1725
          }
        },
        "df1cdc1f6def4c039a7e67dcb7e22ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c58a89ff3e654c7a955b8a070be75ed7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8c0fae561c314931bfc1e60254dcaac4",
            "value": "â€‡8048/8048â€‡[00:01&lt;00:00,â€‡4552.34â€‡examples/s]"
          }
        },
        "e33ae1be66ab49ca84eed95b7151853b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90d75a9bf3414e529241aaf22114e89f",
              "IPY_MODEL_d3bdc6c3ced049bc85d6a10e7fff65ae",
              "IPY_MODEL_357f93453b4e4eaa955410418ba6c4f9"
            ],
            "layout": "IPY_MODEL_3171a03374fa452bb8f300f980f8f879"
          }
        },
        "eae288851f4d42d6a3c8eb12765dba7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f20335768f994e94a8dbd0b3a1846ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a3db096d9049a296511543bf3cd705": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82fb503359ec4594bf9128e1276cd354",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cc2a6f9b1aa49bf989f46524b5584ff",
            "value": 1725
          }
        },
        "faddb02efdd44aa1b3709f4bf356d448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d6c43f2016343fa86df27d93acb5dbd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0c0f6aee07c44c0298eee7487e94802a",
            "value": "Map:â€‡100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
